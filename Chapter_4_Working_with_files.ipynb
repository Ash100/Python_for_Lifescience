{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfN3m57r4l21X+jqb/mezs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ash100/Python_for_Lifescience/blob/main/Chapter_4_Working_with_files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Learn Python for Biological Data Analysis**\n",
        "## **Chapter 4:** Working with Files\n",
        "\n",
        "This course is designed and taught by **Dr. Ashfaq Ahmad**. During teaching I will use all the examples from the Biological Sciences or Life Sciences."
      ],
      "metadata": {
        "id": "4jtCrs4bgPir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìÖ Course Outline\n",
        "\n",
        "---\n",
        "\n",
        "## üèóÔ∏è Foundation (Weeks 1‚Äì2)\n",
        "\n",
        "### üìò Chapter 1: Getting Started with Python and Colab\n",
        "- Introduction to Google Colab interface\n",
        "- Basic Python syntax and data types\n",
        "- Variables, strings, and basic operations\n",
        "- Print statements and comments\n",
        "\n",
        "### üìò Chapter 2: Control Structures\n",
        "- Conditional statements (`if`/`else`)\n",
        "- Loops (`for` and `while`)\n",
        "- Basic functions and scope\n",
        "\n",
        "---\n",
        "\n",
        "## üß¨ Data Handling (Weeks 3‚Äì4)\n",
        "\n",
        "### üìò Chapter 3: Data Structures for Biology\n",
        "- Lists and tuples (storing sequences, experimental data)\n",
        "- Dictionaries (gene annotations, species data)\n",
        "- Sets (unique identifiers, sample collections)\n",
        "\n",
        "### üìò Chapter 4: Working with Files\n",
        "- Reading and writing text files\n",
        "- Handling CSV files (experimental data)\n",
        "- Basic file operations for biological datasets\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Scientific Computing (Weeks 5‚Äì7)\n",
        "\n",
        "### üìò Chapter 5: NumPy for Numerical Data\n",
        "- Arrays for storing experimental measurements\n",
        "- Mathematical operations on datasets\n",
        "- Statistical calculations (mean, median, standard deviation)\n",
        "\n",
        "### üìò Chapter 6: Pandas for Data Analysis\n",
        "- DataFrames for structured biological data\n",
        "- Data cleaning and manipulation\n",
        "- Filtering and grouping experimental results\n",
        "- Handling missing data\n",
        "\n",
        "### üìò Chapter 7: Data Visualization\n",
        "- Matplotlib basics for scientific plots\n",
        "- Creating publication-quality figures\n",
        "- Specialized plots for biological data (histograms, scatter plots, box plots)\n",
        "\n",
        "---\n",
        "\n",
        "## üî¨ Biological Applications (Weeks 8‚Äì10)\n",
        "\n",
        "### üìò Chapter 8: Sequence Analysis\n",
        "- String manipulation for DNA/RNA sequences\n",
        "- Basic sequence operations (reverse complement, transcription)\n",
        "- Reading FASTA files\n",
        "- Simple sequence statistics\n",
        "\n",
        "### üìò Chapter 9: Statistical Analysis for Biology\n",
        "- Hypothesis testing basics\n",
        "- t-tests and chi-square tests\n",
        "- Correlation analysis\n",
        "- Introduction to `scipy.stats`\n",
        "\n",
        "### üìò Chapter 10: Practical Projects\n",
        "- Analyzing gene expression data\n",
        "- Population genetics calculations\n",
        "- Ecological data analysis\n",
        "- Creating reproducible research workflows\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Advanced Topics *(Optional ‚Äì Weeks 11‚Äì12)*\n",
        "\n",
        "### üìò Chapter 11: Bioinformatics Libraries\n",
        "- Introduction to Biopython\n",
        "- Working with biological databases\n",
        "- Phylogenetic analysis basics\n",
        "\n",
        "### üìò Chapter 12: Best Practices\n",
        "- Code organization and documentation\n",
        "- Error handling\n",
        "- Reproducible research practices\n",
        "- Sharing code and results\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Key Teaching Strategies\n",
        "\n",
        "1. Start each chapter with biological context ‚Äì explain why the programming concept matters for their field.\n",
        "2. Use biological datasets throughout ‚Äì gene sequences, experimental measurements, species data.\n",
        "3. Include hands-on exercises after each concept.\n",
        "4. Emphasize reproducibility ‚Äì show how code documents their analysis process.\n",
        "5. Build complexity gradually ‚Äì start with simple examples, then real research scenarios.\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ This progression moves from basic programming concepts to practical biological applications, ensuring students can immediately apply what they learn to their research and coursework.\n"
      ],
      "metadata": {
        "id": "u1FI5JrPgZ7P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Objectives\n",
        "By the end of this chapter, you will be able to:\n",
        "\n",
        "1. Read and write text files containing biological data\n",
        "2. Handle CSV files with experimental data\n",
        "3. Perform basic file operations for biological datasets\n",
        "4. Apply file handling techniques to real biological scenarios"
      ],
      "metadata": {
        "id": "1YnFa9ttgkKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 1:** Reading and Writing Text Files\n",
        "\n",
        "Text files are fundamental for storing and retrieving data. In this section, we'll learn how to read content from existing text files and write new content into them using Python.\n",
        "\n",
        "### 1.1 Reading Text Files\n",
        "\n",
        "Reading a file involves opening it, processing its content, and then closing it. Python's `open()` function is used to open files. When reading, we typically open a file in 'read mode' (`'r'`).\n",
        "\n",
        "### Opening and Closing a File\n",
        "\n",
        "It's crucial to close a file after you're done with it to free up system resources. The `with` statement is the recommended way to handle file operations because it automatically ensures the file is closed, even if errors occur.\n",
        "\n",
        "**Example 1: Reading an entire file**\n",
        "\n",
        "Let's create a dummy file first to demonstrate reading.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v93-p5OCqXBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dummy file for demonstration\n",
        "with open(\"sample.txt\", \"w\") as file:\n",
        "    file.write(\"Hello, this is line 1.\\n\")\n",
        "    file.write(\"This is line 2.\\n\")\n",
        "    file.write(\"And this is line 3.\")"
      ],
      "metadata": {
        "id": "BcBOjLYZkRb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, let's read the entire content of 'sample.txt'\n",
        "with open(\"sample.txt\", \"r\") as file:\n",
        "    content = file.read()\n",
        "    print(\"Content of sample.txt:\")\n",
        "    print(content)"
      ],
      "metadata": {
        "id": "i86nwCuTkd64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### File Modes for Different Purposes\n",
        "\n",
        "When working with files in Python, the `open()` function takes a `mode` argument that specifies how the file will be accessed. Understanding these modes is crucial for performing the desired operations without unintended side effects.\n",
        "\n",
        "| Mode | Description                                                                                             | Behavior if File Exists                               | Behavior if File Does Not Exist                     |\n",
        "| :--- | :------------------------------------------------------------------------------------------------------ | :---------------------------------------------------- | :-------------------------------------------------- |\n",
        "| `'r'`  | **Read Only**: Opens a file for reading. The file pointer is placed at the beginning of the file.     | File content is preserved; reading starts from beginning. | Raises a `FileNotFoundError`.                       |\n",
        "| `'w'`  | **Write**: Opens a file for writing. If the file exists, its content is truncated (erased).           | **Content is overwritten.** | A new, empty file is created.                       |\n",
        "| `'a'`  | **Append**: Opens a file for appending. New data is written to the end of the file.                   | New content is added to the end of the existing content. | A new, empty file is created.                       |\n",
        "| `'r+'` | **Read and Write**: Opens a file for both reading and writing. The file pointer is at the beginning.  | File content is preserved; can read and write from beginning. | Raises a `FileNotFoundError`.                       |\n",
        "| `'x'`  | **Exclusive Creation**: Opens a file for exclusive creation. If the file already exists, the operation fails. | Raises a `FileExistsError`.                           | A new, empty file is created for writing.           |"
      ],
      "metadata": {
        "id": "P8tnxkfYiF4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample DNA sequence file\n",
        "sample_dna = \"\"\"ATCGATCGATCGATCGGCTAGCTAGCT\n",
        "AGCTATTAAGGCCTTAAGGCCCGATCGATCGATCGAT\"\"\"\n",
        "\n",
        "# Write to a file\n",
        "with open('sample_dna.txt', 'w') as file:\n",
        "    file.write(sample_dna)\n",
        "\n",
        "print(\"Sample DNA file created!\")"
      ],
      "metadata": {
        "id": "-SRktDVZx_O5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note.**<br>Triple quotes allow the string to span multiple lines without needing special characters like \\n or string concatenation"
      ],
      "metadata": {
        "id": "c9sofvzll4ho"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMq4FzUsgMsj"
      },
      "outputs": [],
      "source": [
        "# Read the entire file\n",
        "with open('sample_dna.txt', 'r') as file:\n",
        "    content = file.read()\n",
        "    print(\"File contents:\")\n",
        "    print(content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read line by line\n",
        "with open('sample_dna.txt', 'r') as file:\n",
        "    print(\"Reading line by line:\")\n",
        "    for line_number, line in enumerate(file, 1):\n",
        "        print(f\"Line {line_number}: {line.strip()}\")"
      ],
      "metadata": {
        "id": "4UCvnLoJbsi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2 Processing FASTA Files**"
      ],
      "metadata": {
        "id": "zqdUxcehfBtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample FASTA file\n",
        "fasta_content = \"\"\">seq1 Human hemoglobin alpha chain\n",
        "MVLSPADKTNVKAAWGKVGAHAGEYGAEALERMFLSFPTTKTYFPHFDLSHGSAQVKGHG\n",
        "KKVADALTNAVAHVDDMPNALSALSDLHAHKLRVDPVNFKLLSHCLLVTLAAHLPAEFTP\n",
        "AVHASLDKFLASVSTVLTSKYR\n",
        "\n",
        ">seq2 Human hemoglobin beta chain\n",
        "MVHLTPEEKSAVTALWGKVNVDEVGGEALGRLLVVYPWTQRFFESFGDLSTPDAVMGNPK\n",
        "VKAHGKKVLGAFSDGLAHLDNLKGTFATLSELHCDKLHVDPENFRLLGNVLVCVLAHHFG\n",
        "KEFTPPVQAAYQKVVAGVANALAHKYH\"\"\"\n",
        "\n",
        "with open('sample_sequences.fasta', 'w') as file:\n",
        "    file.write(fasta_content)\n",
        "\n",
        "print(\"FASTA file created!\")"
      ],
      "metadata": {
        "id": "G0MeBrHkq38X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we are going to Parse the **FASTA** file.\n",
        "### **Why Parse FASTA?**\n",
        "\n",
        "Often, we need to extract specific information from FASTA files, like:\n",
        "* Just the sequence headers.\n",
        "* Just the sequences themselves.\n",
        "* Mapping headers to their corresponding sequences."
      ],
      "metadata": {
        "id": "7bF1ZStKm2S4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to parse FASTA file\n",
        "def parse_fasta(filename):\n",
        "    \"\"\"Parse a FASTA file and return sequences as a dictionary\"\"\"\n",
        "    sequences = {}\n",
        "    current_header = None\n",
        "    current_sequence = []\n",
        "\n",
        "    with open(filename, 'r') as file:\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if line.startswith('>'):\n",
        "                # Save previous sequence if exists\n",
        "                if current_header:\n",
        "                    sequences[current_header] = ''.join(current_sequence)\n",
        "                # Start new sequence\n",
        "                current_header = line[1:]  # Remove '>'\n",
        "                current_sequence = []\n",
        "            else:\n",
        "                current_sequence.append(line)\n",
        "\n",
        "        # Save last sequence\n",
        "        if current_header:\n",
        "            sequences[current_header] = ''.join(current_sequence)\n",
        "\n",
        "    return sequences\n",
        "\n",
        "# Parse the FASTA file\n",
        "sequences = parse_fasta('sample_sequences.fasta')\n",
        "\n",
        "# Display results\n",
        "for header, sequence in sequences.items():\n",
        "    print(f\"Header: {header}\")\n",
        "    print(f\"Sequence length: {len(sequence)}\")\n",
        "    print(f\"First 50 characters: {sequence[:50]}...\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "QkObT9OFfUOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3 Writing Analysis Results**"
      ],
      "metadata": {
        "id": "W7247obHrMmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze sequences and write results\n",
        "def analyze_sequence(sequence):\n",
        "    \"\"\"Analyze a DNA/protein sequence\"\"\"\n",
        "    analysis = {\n",
        "        'length': len(sequence),\n",
        "        'A_count': sequence.count('A'),\n",
        "        'T_count': sequence.count('T'),\n",
        "        'G_count': sequence.count('G'),\n",
        "        'C_count': sequence.count('C'),\n",
        "        'gc_content': (sequence.count('G') + sequence.count('C')) / len(sequence) * 100\n",
        "    }\n",
        "    return analysis\n",
        "\n",
        "# Analyze all sequences and write results\n",
        "with open('sequence_analysis.txt', 'w') as output_file:\n",
        "    output_file.write(\"Sequence Analysis Results\\n\")\n",
        "    output_file.write(\"=\" * 50 + \"\\n\\n\")\n",
        "\n",
        "    for header, sequence in sequences.items():\n",
        "        analysis = analyze_sequence(sequence)\n",
        "        output_file.write(f\"Sequence: {header}\\n\")\n",
        "        output_file.write(f\"Length: {analysis['length']} amino acids\\n\")\n",
        "        output_file.write(f\"Amino acid composition:\\n\")\n",
        "        output_file.write(f\"  A: {analysis['A_count']}\\n\")\n",
        "        output_file.write(f\"  T: {analysis['T_count']}\\n\")\n",
        "        output_file.write(f\"  G: {analysis['G_count']}\\n\")\n",
        "        output_file.write(f\"  C: {analysis['C_count']}\\n\")\n",
        "        output_file.write(f\"GC Content: {analysis['gc_content']:.2f}%\\n\")\n",
        "        output_file.write(\"-\" * 30 + \"\\n\")\n",
        "\n",
        "print(\"Analysis complete! Results written to sequence_analysis.txt\")\n",
        "\n",
        "# Display the results\n",
        "with open('sequence_analysis.txt', 'r') as file:\n",
        "    print(file.read())"
      ],
      "metadata": {
        "id": "y24ZgiRxrNoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 2.** Handling CSV Files (Experimental Data)\n",
        "**2.1 Basic CSV Operations**\n",
        "\n",
        "CSV stands for **Comma Separated Values**. It's a simple, plain text file format used to store tabular data (numbers and text) in a structured way. Each line in the file represents a data record, and each record consists of one or more fields, separated by commas."
      ],
      "metadata": {
        "id": "YzvhQsUJrVH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dummy CSV file\n",
        "csv_data = \"\"\"Name,Age,City\n",
        "Alice,30,New York\n",
        "Bob,24,London\n",
        "Charlie,35,Paris\n",
        "David,28,\"San Francisco\"\n",
        "\"\"\"\n",
        "with open(\"people.csv\", \"w\") as f:\n",
        "    f.write(csv_data.strip())\n",
        "\n",
        "print(\"Created 'people.csv' for demonstration.\")"
      ],
      "metadata": {
        "id": "IPJxDZtdoWfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the above CSV file\n",
        "import csv\n",
        "\n",
        "print(\"\\nReading 'people.csv' with csv.reader:\")\n",
        "with open('people.csv', 'r', newline='') as file:\n",
        "    csv_reader = csv.reader(file)\n",
        "    header = next(csv_reader) # Read the header row\n",
        "    print(f\"Header: {header}\")\n",
        "\n",
        "    for row in csv_reader:\n",
        "        print(f\"Row: {row}\")\n",
        "        # You can access elements by index, e.g., row[0] for Name, row[1] for Age\n",
        "        # print(f\"Name: {row[0]}, Age: {row[1]}, City: {row[2]}\")"
      ],
      "metadata": {
        "id": "ktg69-2nowY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Create sample experimental data\n",
        "experimental_data = [\n",
        "    ['Sample_ID', 'Treatment', 'Concentration', 'Growth_Rate', 'Viability'],\n",
        "    ['S001', 'Control', 0, 2.3, 98.5],\n",
        "    ['S002', 'Drug_A', 10, 1.8, 85.2],\n",
        "    ['S003', 'Drug_A', 50, 1.2, 72.1],\n",
        "    ['S004', 'Drug_A', 100, 0.8, 45.3],\n",
        "    ['S005', 'Drug_B', 10, 2.1, 92.1],\n",
        "    ['S006', 'Drug_B', 50, 1.5, 78.9],\n",
        "    ['S007', 'Drug_B', 100, 1.0, 55.7],\n",
        "    ['S008', 'Control', 0, 2.4, 97.8]\n",
        "]\n",
        "\n",
        "# Write to CSV file\n",
        "with open('experimental_data.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(experimental_data)\n",
        "\n",
        "print(\"Experimental data CSV created!\")"
      ],
      "metadata": {
        "id": "fsxhn2IerV6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and display CSV data\n",
        "with open('experimental_data.csv', 'r') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    print(\"Experimental Data:\")\n",
        "    for row in reader:\n",
        "        print('\\t'.join(row))"
      ],
      "metadata": {
        "id": "UIW_DQhNf9Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2 Working with CSV Using DictReader**"
      ],
      "metadata": {
        "id": "6iByDVX9gBBX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `csv.DictReader` class is a powerful and highly recommended tool when you're dealing with CSV files, especially when your data has a clear header row. Instead of giving you lists of strings (where you have to remember index numbers like `row[0]`, `row[1]`), `DictReader` provides each row as a dictionary. This makes your code much more readable and less prone to errors if the column order changes.\n",
        "\n",
        "### Why Use `DictReader`?\n",
        "\n",
        "* **Readability:** Access data by column name (e.g., `row['Name']`) instead of by index (e.g., `row[0]`).\n",
        "* **Maintainability:** Your code is more robust. If a column is reordered in the CSV file, your code won't break as long as the column name remains the same.\n",
        "* **Convenience:** Directly provides data in a key-value pair format, which is often easier to work with.\n",
        "\n",
        "### 1. Basic Usage of `csv.DictReader`\n",
        "\n",
        "To use `DictReader`, you simply pass your opened file object to it. It automatically reads the first row as the header and uses those values as dictionary keys for subsequent rows."
      ],
      "metadata": {
        "id": "l2NF5d_dpZTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets pass the **experimental_data** to it"
      ],
      "metadata": {
        "id": "4bP8UOMqqJOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV as dictionaries\n",
        "with open('experimental_data.csv', 'r') as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "\n",
        "    print(\"Data as dictionaries:\")\n",
        "    for row in reader:\n",
        "        print(f\"Sample {row['Sample_ID']}: {row['Treatment']} treatment\")\n",
        "        print(f\"  Concentration: {row['Concentration']} ŒºM\")\n",
        "        print(f\"  Growth Rate: {row['Growth_Rate']} /hr\")\n",
        "        print(f\"  Viability: {row['Viability']}%\")\n",
        "        print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "Zctu0kKygFWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3 Data Analysis and Filtering** <br>\n",
        "Data analysis involves inspecting, cleaning, transforming, and modeling data with the goal of discovering useful information, informing conclusions, and supporting decision-making. Data filtration is a key part of this, allowing us to select specific subsets of data that meet certain criteria.\n",
        "\n",
        "### 1. Basic Filtration and Analysis (Using Python Built-ins)\n",
        "\n",
        "Before diving into specialized libraries, it's good to understand how to perform basic operations using standard Python lists and dictionaries, especially when you've parsed CSVs using `csv.DictReader`."
      ],
      "metadata": {
        "id": "EsTAtfCegGX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure people.csv exists\n",
        "csv_data = \"\"\"Name,Age,City,Occupation,Salary\n",
        "Alice,30,New York,Engineer,75000\n",
        "Bob,24,London,Designer,60000\n",
        "Charlie,35,Paris,Manager,90000\n",
        "David,28,\"San Francisco\",Engineer,80000\n",
        "Eve,22,Berlin,Analyst,55000\n",
        "Frank,40,Tokyo,Manager,100000\n",
        "Grace,29,Sydney,Designer,62000\n",
        "\"\"\"\n",
        "with open(\"people.csv\", \"w\") as f:\n",
        "    f.write(csv_data.strip())\n",
        "\n",
        "print(\"Ensured 'people.csv' for demonstration.\")\n",
        "\n",
        "import csv\n",
        "\n",
        "# Load the data into a list of dictionaries\n",
        "people_data = []\n",
        "with open('people.csv', 'r', newline='') as file:\n",
        "    csv_dict_reader = csv.DictReader(file)\n",
        "    for row in csv_dict_reader:\n",
        "        # Convert numeric values from string to appropriate types\n",
        "        try:\n",
        "            row['Age'] = int(row['Age'])\n",
        "            row['Salary'] = int(row['Salary'])\n",
        "        except ValueError:\n",
        "            print(f\"Warning: Could not convert numeric values in row: {row}\")\n",
        "            continue # Skip row if conversion fails\n",
        "        people_data.append(row)\n",
        "\n",
        "print(\"\\nLoaded data (first 3 records):\")\n",
        "for i, person in enumerate(people_data[:3]):\n",
        "    print(person)\n",
        "    if i == 2: break"
      ],
      "metadata": {
        "id": "uFx1HatVrI5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze experimental data\n",
        "def analyze_experimental_data(filename):\n",
        "    \"\"\"Analyze experimental data from CSV file\"\"\"\n",
        "    treatments = {}\n",
        "\n",
        "    with open(filename, 'r') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "\n",
        "        for row in reader:\n",
        "            treatment = row['Treatment']\n",
        "            concentration = float(row['Concentration'])\n",
        "            growth_rate = float(row['Growth_Rate'])\n",
        "            viability = float(row['Viability'])\n",
        "\n",
        "            if treatment not in treatments:\n",
        "                treatments[treatment] = {\n",
        "                    'concentrations': [],\n",
        "                    'growth_rates': [],\n",
        "                    'viabilities': []\n",
        "                }\n",
        "\n",
        "            treatments[treatment]['concentrations'].append(concentration)\n",
        "            treatments[treatment]['growth_rates'].append(growth_rate)\n",
        "            treatments[treatment]['viabilities'].append(viability)\n",
        "\n",
        "    return treatments\n",
        "\n",
        "# Analyze the data\n",
        "results = analyze_experimental_data('experimental_data.csv')\n",
        "\n",
        "# Calculate statistics\n",
        "for treatment, data in results.items():\n",
        "    print(f\"\\nTreatment: {treatment}\")\n",
        "    print(f\"Number of samples: {len(data['growth_rates'])}\")\n",
        "    print(f\"Average growth rate: {sum(data['growth_rates'])/len(data['growth_rates']):.2f} /hr\")\n",
        "    print(f\"Average viability: {sum(data['viabilities'])/len(data['viabilities']):.2f}%\")\n",
        "    print(f\"Concentration range: {min(data['concentrations'])}-{max(data['concentrations'])} ŒºM\")"
      ],
      "metadata": {
        "id": "IGGSdFxvgKoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.4 Writing Processed Data**"
      ],
      "metadata": {
        "id": "vudF34_VgPZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Process and write summary data\n",
        "summary_data = []\n",
        "summary_data.append(['Treatment', 'Sample_Count', 'Avg_Growth_Rate', 'Avg_Viability', 'Max_Concentration'])\n",
        "\n",
        "for treatment, data in results.items():\n",
        "    avg_growth = sum(data['growth_rates']) / len(data['growth_rates'])\n",
        "    avg_viability = sum(data['viabilities']) / len(data['viabilities'])\n",
        "    max_concentration = max(data['concentrations'])\n",
        "    sample_count = len(data['growth_rates'])\n",
        "\n",
        "    summary_data.append([treatment, sample_count, f\"{avg_growth:.2f}\", f\"{avg_viability:.2f}\", max_concentration])\n",
        "\n",
        "# Write summary to new CSV\n",
        "with open('treatment_summary.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(summary_data)\n",
        "\n",
        "print(\"Summary data written to treatment_summary.csv\")\n",
        "\n",
        "# Display summary\n",
        "with open('treatment_summary.csv', 'r') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    print(\"\\nTreatment Summary:\")\n",
        "    for row in reader:\n",
        "        print('\\t'.join(row))"
      ],
      "metadata": {
        "id": "6Hz3DpsigSMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 3.** Basic File Operations for Biological Datasets\n",
        "Biological datasets often come in various file formats (e.g., FASTA, FASTQ, BAM, VCF, CSV, TSV) and can be quite large. Efficiently handling these files is crucial for bioinformatics workflows. This section covers fundamental file operations in Python, focusing on common tasks encountered with biological data.<br>\n",
        "**3.1 File System Operations**\n",
        "\n",
        "The `os` `glob` and `shutil` modules provide functions for interacting with the file system, such as checking file **existence**, **moving**, **copying**, and **deleting** files and directories."
      ],
      "metadata": {
        "id": "Fw54vdDEgZLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Create a directory structure for biological data\n",
        "directories = ['data', 'data/sequences', 'data/experiments', 'results']\n",
        "\n",
        "for directory in directories:\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "        print(f\"Created directory: {directory}\")\n",
        "\n",
        "# Move files to appropriate directories\n",
        "import shutil\n",
        "\n",
        "# Move sequence files\n",
        "if os.path.exists('sample_sequences.fasta'):\n",
        "    shutil.move('sample_sequences.fasta', 'data/sequences/')\n",
        "    print(\"Moved FASTA file to sequences directory\")\n",
        "\n",
        "if os.path.exists('sample_dna.txt'):\n",
        "    shutil.move('sample_dna.txt', 'data/sequences/')\n",
        "    print(\"Moved DNA file to sequences directory\")\n",
        "\n",
        "# Move experimental data\n",
        "if os.path.exists('experimental_data.csv'):\n",
        "    shutil.move('experimental_data.csv', 'data/experiments/')\n",
        "    print(\"Moved experimental data to experiments directory\")\n",
        "\n",
        "# Move results\n",
        "if os.path.exists('sequence_analysis.txt'):\n",
        "    shutil.move('sequence_analysis.txt', 'results/')\n",
        "    print(\"Moved analysis results to results directory\")\n",
        "\n",
        "if os.path.exists('treatment_summary.csv'):\n",
        "    shutil.move('treatment_summary.csv', 'results/')\n",
        "    print(\"Moved summary to results directory\")"
      ],
      "metadata": {
        "id": "CehFBg8ZgvMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2 Batch Processing Files**"
      ],
      "metadata": {
        "id": "Ro0w7JfFgzXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create multiple sequence files for batch processing\n",
        "sample_sequences = {\n",
        "    'gene1.fasta': '>gene1\\nATCGATCGATCGATCG\\nGCTAGCTAGCTAGCTA',\n",
        "    'gene2.fasta': '>gene2\\nTTAAGGCCTTAAGGCC\\nCGATCGATCGATCGAT',\n",
        "    'gene3.fasta': '>gene3\\nGGCCTTAAGGCCTTAA\\nATCGATCGATCGATCG'\n",
        "}\n",
        "\n",
        "# Write sample files\n",
        "for filename, content in sample_sequences.items():\n",
        "    with open(f'data/sequences/{filename}', 'w') as file:\n",
        "        file.write(content)\n",
        "\n",
        "print(\"Created sample sequence files for batch processing\")"
      ],
      "metadata": {
        "id": "NBsIUndZgzuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch process all FASTA files\n",
        "def batch_process_fasta_files(directory):\n",
        "    \"\"\"Process all FASTA files in a directory\"\"\"\n",
        "    fasta_files = glob.glob(os.path.join(directory, '*.fasta'))\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for filepath in fasta_files:\n",
        "        filename = os.path.basename(filepath)\n",
        "        print(f\"Processing: {filename}\")\n",
        "\n",
        "        sequences = parse_fasta(filepath)\n",
        "\n",
        "        for header, sequence in sequences.items():\n",
        "            analysis = analyze_sequence(sequence)\n",
        "            results[filename] = {\n",
        "                'header': header,\n",
        "                'analysis': analysis\n",
        "            }\n",
        "\n",
        "    return results\n",
        "\n",
        "# Process all FASTA files\n",
        "batch_results = batch_process_fasta_files('data/sequences/')\n",
        "\n",
        "# Write batch results\n",
        "with open('results/batch_analysis.txt', 'w') as output_file:\n",
        "    output_file.write(\"Batch Analysis Results\\n\")\n",
        "    output_file.write(\"=\" * 50 + \"\\n\\n\")\n",
        "\n",
        "    for filename, data in batch_results.items():\n",
        "        output_file.write(f\"File: {filename}\\n\")\n",
        "        output_file.write(f\"Sequence: {data['header']}\\n\")\n",
        "        analysis = data['analysis']\n",
        "        output_file.write(f\"Length: {analysis['length']} bp\\n\")\n",
        "        output_file.write(f\"GC Content: {analysis['gc_content']:.2f}%\\n\")\n",
        "        output_file.write(\"-\" * 30 + \"\\n\")\n",
        "\n",
        "print(\"Batch analysis complete!\")"
      ],
      "metadata": {
        "id": "voN_s5g1g72A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3 Error Handling and File Validation**"
      ],
      "metadata": {
        "id": "nqLpKtG3g_f3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_file_reader(filename):\n",
        "    \"\"\"Safely read a file with error handling\"\"\"\n",
        "    try:\n",
        "        with open(filename, 'r') as file:\n",
        "            content = file.read()\n",
        "            return content\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{filename}' not found!\")\n",
        "        return None\n",
        "    except PermissionError:\n",
        "        print(f\"Error: Permission denied for file '{filename}'!\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file '{filename}': {e}\")\n",
        "        return None\n",
        "\n",
        "# Test error handling\n",
        "print(\"Testing error handling:\")\n",
        "content = safe_file_reader('nonexistent_file.txt')\n",
        "print(f\"Content: {content}\")\n",
        "\n",
        "# Test with existing file\n",
        "content = safe_file_reader('results/batch_analysis.txt')\n",
        "if content:\n",
        "    print(f\"Successfully read file. Length: {len(content)} characters\")"
      ],
      "metadata": {
        "id": "LcJUxr7nhBxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.4 File Information and Statistics**"
      ],
      "metadata": {
        "id": "lOkDlHpZhGM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_file_info(filepath):\n",
        "    \"\"\"Get information about a file\"\"\"\n",
        "    try:\n",
        "        stats = os.stat(filepath)\n",
        "        return {\n",
        "            'size': stats.st_size,\n",
        "            'modified': stats.st_mtime,\n",
        "            'exists': True\n",
        "        }\n",
        "    except:\n",
        "        return {'exists': False}\n",
        "\n",
        "# Get information about all files in results directory\n",
        "results_files = glob.glob('results/*')\n",
        "\n",
        "print(\"File Information:\")\n",
        "print(\"=\" * 50)\n",
        "for filepath in results_files:\n",
        "    info = get_file_info(filepath)\n",
        "    if info['exists']:\n",
        "        filename = os.path.basename(filepath)\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"  Size: {info['size']} bytes\")\n",
        "        print(f\"  Modified: {info['modified']}\")\n",
        "        print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "b9cPU82XhKSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Practical Exercises\n",
        "**Exercise 1: Gene Expression Data Processing**"
      ],
      "metadata": {
        "id": "s_S05L4ehN9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample gene expression data\n",
        "gene_expression_data = [\n",
        "    ['Gene_ID', 'Gene_Name', 'Control_1', 'Control_2', 'Treatment_1', 'Treatment_2'],\n",
        "    ['G001', 'GAPDH', 1000, 1050, 980, 1020],\n",
        "    ['G002', 'ACTB', 800, 820, 750, 780],\n",
        "    ['G003', 'TP53', 200, 180, 450, 420],\n",
        "    ['G004', 'BRCA1', 150, 160, 300, 280],\n",
        "    ['G005', 'MYC', 300, 280, 150, 170]\n",
        "]\n",
        "\n",
        "with open('data/experiments/gene_expression.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(gene_expression_data)\n",
        "\n",
        "print(\"Gene expression data created!\")"
      ],
      "metadata": {
        "id": "qEhnccbkhVTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** Write a function to calculate fold change for each gene and identify significantly changed genes."
      ],
      "metadata": {
        "id": "ZfufjCdyhdY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 2: Quality Control for Sequence Data**"
      ],
      "metadata": {
        "id": "roe_cnIRhjgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample sequence with quality issues\n",
        "problematic_sequences = \"\"\">seq_with_N\n",
        "ATCGATCGATCNNNGATCGATCG\n",
        ">short_seq\n",
        "ATCG\n",
        ">seq_with_gaps\n",
        "ATCGATCG---ATCGATCG\n",
        ">normal_seq\n",
        "ATCGATCGATCGATCGATCG\"\"\"\n",
        "\n",
        "with open('data/sequences/quality_check.fasta', 'w') as file:\n",
        "    file.write(problematic_sequences)\n",
        "\n",
        "print(\"Quality check sequences created!\")"
      ],
      "metadata": {
        "id": "8EnKE6oXhc2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** Write a quality control function that identifies and reports sequences with issues."
      ],
      "metadata": {
        "id": "KLtoNEnNhzVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary**<br>\n",
        "In this chapter, you learned:\n",
        "\n",
        "**1. Text File Operations:** How to read and write text files, including biological data formats like FASTA<br>\n",
        "**2. CSV File Handling:** Working with experimental data in CSV format using Python's csv module<br>\n",
        "**3. File System Operations:** Organizing biological datasets with directories and batch processing<br>\n",
        "**4. Error Handling:** Implementing robust file operations with proper error handling<br>\n",
        "**5. Best Practices:** Following Python conventions for file handling in biological data analysis<br>\n",
        "\n",
        "These skills form the foundation for working with biological datasets and will be essential for more advanced data analysis tasks."
      ],
      "metadata": {
        "id": "srDAnB17ijAW"
      }
    }
  ]
}